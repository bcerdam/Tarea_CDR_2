{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427da18d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Parte 1\n",
    "\n",
    "### 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f62c863",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Elegimos un dataset llamado [\\\"salary.csv\\\"](https://www.kaggle.com/datasets/ayessa/salary-prediction-classification) que tiene de utilidad original crear un algoritmo predictivo para poder predecir si una persona gana más de 50.000 USD al año. Creer que existe una desigualdad en la proporción de quien gana más dependiendo del sexo en este dataset es válido, es por esta razón que elegimos esta dataset para poder estudiar su posible sesgo.\n",
    "\n",
    "Primero, importar los paquetes necesarios para poder utilizar AIF360 y el dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edda625f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from IPython.display import Markdown, display\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d20cdbd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2\n",
    "\n",
    "Preprocesamos el dataset para poder ocupar las funciones de AIF360."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c87bd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "salary = pd.read_csv('salary.csv')\n",
    "\n",
    "salary['sex'] = salary['sex'].apply(lambda x: 0 if x==' Female' else 1)\n",
    "salary['salary'] = salary['salary'].apply(lambda x: 1 if x==' >50K' else 0)\n",
    "salary_aif = StandardDataset(salary, label_name='salary', protected_attribute_names=['sex'],\n",
    "                              privileged_classes=[[1]], favorable_classes=[1],\n",
    "                                features_to_drop=['workclass', 'fnlwgt', 'education', 'marital-status',\n",
    "                                                  'occupation', 'relationship', 'race', 'native-country'])\n",
    "\n",
    "\n",
    "salary_aif_train, salary_aif_test = salary_aif.split([0.7], shuffle=True)\n",
    "# salary_aif_test, salary_val_aif = salary_aif_test.split([0.7], shuffle=True)\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bd54922",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 6) (22792, 6) (9769, 6)\n"
     ]
    }
   ],
   "source": [
    "print(salary_aif.features.shape, salary_aif_train.features.shape, salary_aif_test.features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45761bdc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ahora el dataset puede ocupar funciones de AIF360, ya que fue procesado correctamente.\n",
    "\n",
    "### 1.3\n",
    "\n",
    "Seleccionamos al grupo \\\"Male\\\" como privilegiado, y \\\"Female\\\" como no privilegiado. Decidimos hacer esto ya que el número de articulos que apoya esta suposicion es bien grande. [Por ejemplo](https://www.payscale.com/gender-lifetime-earnings-gap) en este articulo establecen que los hombres ganan más que las mujeres, pero no *tanto* más cuando trabajan el mismo oficio.\n",
    "\n",
    "### 1.4\n",
    "\n",
    "Vamos a calcular dos métricas. La diferencia en el promedio, en donde se resta los resultados favorables para el grupo privilegiado con el grupo no privilegiado. También vamos a calcular \"Disparate Impact\" para poder observar la proporción de resultados favorables para el grupo no privilegiado en comparación del grupo privilegiado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa55628",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diferencia en promedio = -0.195396\n",
      "Disparidad de impacto = 0.363245\n"
     ]
    }
   ],
   "source": [
    "mean_train = BinaryLabelDatasetMetric(salary_aif_train,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Diferencia en promedio = %f\" % mean_train.mean_difference())\n",
    "print(\"Disparidad de impacto = %f\" % mean_train.disparate_impact())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0e994",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Como el resultado de la diferencia en promedio (mean_difference) es negativo, indica que hay menos resultados favorables para el grupo no privilegiado, por lo que si existe un sesgo. También tenemos que la disparidad de impacto es bastante baja, por lo que el grupo privilegiado en proporción ganan más que el grupo no privilegiado, lo óptimo es que la disparidad de impacto tienda a 1.\n",
    "\n",
    "Como el resultado de la diferencia en promedio (mean_difference) es negativo, indica que hay menos resultados favorables para el grupo no privilegiado, por lo que si existe un sesgo.\n",
    "\n",
    "### 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a7d86a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14746f3e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (22792, 7)\n",
      "Val set: (2931, 7)\n",
      "Test set: (6838, 7)\n"
     ]
    }
   ],
   "source": [
    "salary_aif_test, salary_val_aif = salary_aif_test.split([0.7], shuffle=True)\n",
    "\n",
    "train_df, _ = salary_aif_train.convert_to_dataframe()\n",
    "val_df, _ = salary_val_aif.convert_to_dataframe()\n",
    "test_df, _ = salary_aif_test.convert_to_dataframe()\n",
    "\n",
    "print(f'Train set: {train_df.shape}')\n",
    "print(f'Val set: {val_df.shape}')\n",
    "print(f'Test set: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4127b14d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_df.drop('salary', axis=1)\n",
    "y_train = train_df.salary\n",
    "\n",
    "x_val = val_df.drop('salary', axis=1)\n",
    "y_val = val_df.salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a399fe7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression(C=0.5, penalty='l1', solver='liblinear')\n",
    "logistic.fit(x_train, y_train, sample_weight=None)\n",
    "\n",
    "linear = LinearRegression()\n",
    "linear.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a15a4472",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, X, y_true):\n",
    "    if isinstance(model, LogisticRegression):\n",
    "        y_pred = model.predict_proba(X)[:, 1]\n",
    "    elif isinstance(model, LinearRegression):\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred >= 0.5)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    return accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f521af4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresion logistica\n",
      "Accuracy: 0.8225861480723302\n",
      "AUC: 0.8417734073349594\n",
      "\n",
      "Regresion lineal\n",
      "Accuracy: 0.8106448311156602\n",
      "AUC: 0.8327195990400214\n"
     ]
    }
   ],
   "source": [
    "print('Regresion logistica')\n",
    "accuracy, auc = evaluate(logistic, x_val, y_val)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "print('\\nRegresion lineal')\n",
    "accuracy, auc = evaluate(linear, x_val, y_val)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'AUC: {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b10effd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logistic_pred_df = train_df.copy()\n",
    "logistic_pred_df['predict'] = logistic.predict(x_train)\n",
    "\n",
    "linear_pred_df = train_df.copy()\n",
    "linear_pred_df['predict'] = linear.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73968218",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "text/plain": "        age  education-num  sex  capital-gain  capital-loss  hours-per-week  \\\n12319  29.0           13.0  1.0           0.0           0.0            75.0   \n6964   29.0           16.0  1.0           0.0           0.0            60.0   \n21840  56.0           16.0  1.0           0.0           0.0            50.0   \n19520  63.0           13.0  1.0           0.0           0.0            40.0   \n26360  51.0           13.0  1.0           0.0           0.0            50.0   \n...     ...            ...  ...           ...           ...             ...   \n11321  75.0           10.0  1.0           0.0        1735.0            40.0   \n10328  70.0           14.0  1.0           0.0           0.0             8.0   \n15323  29.0           14.0  1.0           0.0           0.0            60.0   \n32340  75.0           14.0  1.0           0.0           0.0            45.0   \n16868  53.0           12.0  1.0        2407.0           0.0            99.0   \n\n       salary  predict  \n12319     0.0      1.0  \n6964      0.0      1.0  \n21840     0.0      1.0  \n19520     0.0      1.0  \n26360     0.0      1.0  \n...       ...      ...  \n11321     0.0      1.0  \n10328     0.0      1.0  \n15323     0.0      1.0  \n32340     0.0      1.0  \n16868     0.0      1.0  \n\n[898 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>education-num</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>salary</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12319</th>\n      <td>29.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>75.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6964</th>\n      <td>29.0</td>\n      <td>16.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>21840</th>\n      <td>56.0</td>\n      <td>16.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>19520</th>\n      <td>63.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>26360</th>\n      <td>51.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11321</th>\n      <td>75.0</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1735.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10328</th>\n      <td>70.0</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>15323</th>\n      <td>29.0</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>32340</th>\n      <td>75.0</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>45.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16868</th>\n      <td>53.0</td>\n      <td>12.0</td>\n      <td>1.0</td>\n      <td>2407.0</td>\n      <td>0.0</td>\n      <td>99.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>898 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positives\n",
    "logistic_pred_df[logistic_pred_df['salary'] == 0][logistic_pred_df['predict'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e7bdbad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        age  education-num  sex  capital-gain  capital-loss  hours-per-week  \\\n22278  27.0           10.0  0.0           0.0           0.0            44.0   \n8950   27.0           13.0  0.0           0.0           0.0            40.0   \n7838   25.0           12.0  1.0           0.0           0.0            40.0   \n16505  46.0            3.0  1.0           0.0        1902.0            40.0   \n19140  45.0            7.0  1.0           0.0        2824.0            76.0   \n...     ...            ...  ...           ...           ...             ...   \n19631  34.0           13.0  1.0           0.0           0.0            40.0   \n29694  56.0           13.0  0.0           0.0           0.0            40.0   \n16546  34.0           11.0  1.0           0.0           0.0            40.0   \n17973  25.0            9.0  1.0           0.0           0.0            40.0   \n8057   36.0            9.0  1.0        3464.0           0.0            30.0   \n\n       salary  predict  \n22278     0.0      0.0  \n8950      0.0      0.0  \n7838      0.0      0.0  \n16505     0.0      0.0  \n19140     1.0      1.0  \n...       ...      ...  \n19631     1.0      0.0  \n29694     0.0      0.0  \n16546     0.0      0.0  \n17973     0.0      0.0  \n8057      0.0      0.0  \n\n[22792 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>education-num</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>salary</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22278</th>\n      <td>27.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>44.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8950</th>\n      <td>27.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7838</th>\n      <td>25.0</td>\n      <td>12.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16505</th>\n      <td>46.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1902.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19140</th>\n      <td>45.0</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2824.0</td>\n      <td>76.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19631</th>\n      <td>34.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>29694</th>\n      <td>56.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16546</th>\n      <td>34.0</td>\n      <td>11.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17973</th>\n      <td>25.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8057</th>\n      <td>36.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>3464.0</td>\n      <td>0.0</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>22792 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbfcf7bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_df.drop('salary', axis=1)\n",
    "y_train = train_df.salary\n",
    "\n",
    "x_val = val_df.drop('salary', axis=1)\n",
    "y_val = val_df.salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b540f62f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logistic = LogisticRegression(C=0.5, penalty='l1', solver='liblinear')\n",
    "logistic.fit(x_train, y_train, sample_weight=None)\n",
    "\n",
    "linear = LinearRegression()\n",
    "linear.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb860a46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, X, y_true):\n",
    "    if isinstance(model, LogisticRegression):\n",
    "        y_pred = model.predict_proba(X)[:, 1]\n",
    "    elif isinstance(model, LinearRegression):\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred >= 0.5)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    return accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e2f9f7e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresion logistica\n",
      "Accuracy: 0.8229273285568065\n",
      "AUC: 0.8417622782864408\n",
      "\n",
      "Regresion lineal\n",
      "Accuracy: 0.8106448311156602\n",
      "AUC: 0.8327195990400214\n"
     ]
    }
   ],
   "source": [
    "print('Regresion logistica')\n",
    "accuracy, auc = evaluate(logistic, x_val, y_val)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "print('\\nRegresion lineal')\n",
    "accuracy, auc = evaluate(linear, x_val, y_val)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'AUC: {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "517b9b30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diferencia en promedio regresion logistica = -0.195396\n",
      "Disparidad de impacto regresion logistica = 0.363245\n",
      "Diferencia en promedio regresion lineal = -0.195396\n",
      "Disparidad de impacto regresion lineal = 0.363245\n"
     ]
    }
   ],
   "source": [
    "logistic_aif360 = StandardDataset(logistic_pred_df, label_name='salary', protected_attribute_names=['sex'],\n",
    "                              privileged_classes=[[1]], favorable_classes=[1])\n",
    "\n",
    "linear_aif360 = StandardDataset(linear_pred_df, label_name='salary', protected_attribute_names=['sex'],\n",
    "                                  privileged_classes=[[1]], favorable_classes=[1])\n",
    "\n",
    "\n",
    "\n",
    "logistic_metrics = BinaryLabelDatasetMetric(logistic_aif360,\n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "\n",
    "linear_metrics = BinaryLabelDatasetMetric(linear_aif360,\n",
    "                                          unprivileged_groups=unprivileged_groups,\n",
    "                                          privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Diferencia en promedio regresion logistica = %f\" % logistic_metrics.mean_difference())\n",
    "print(\"Disparidad de impacto regresion logistica = %f\" % logistic_metrics.disparate_impact())\n",
    "\n",
    "print(\"Diferencia en promedio regresion lineal = %f\" % linear_metrics.mean_difference())\n",
    "print(\"Disparidad de impacto regresion lineal = %f\" % linear_metrics.disparate_impact())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b22a20eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logistic_pred_df = train_df.copy()\n",
    "logistic_pred_df['predict'] = logistic.predict(x_train)\n",
    "\n",
    "linear_pred_df = train_df.copy()\n",
    "linear_pred_df['predict'] = linear.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec638edd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b14587",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.1437082624067042"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positives sex == 0\n",
    "fp_0 = logistic_pred_df[logistic_pred_df['salary'] == 0][logistic_pred_df['predict'] == 1][logistic_pred_df['sex'] == 0].shape[0]\n",
    "\n",
    "# false positives sex == 1\n",
    "fp_1 = logistic_pred_df[logistic_pred_df['salary'] == 0][logistic_pred_df['predict'] == 1][logistic_pred_df['sex'] == 1].shape[0]\n",
    "\n",
    "# false negetive sex == 0\n",
    "fn_0 = logistic_pred_df[logistic_pred_df['salary'] == 1][logistic_pred_df['predict'] == 0][logistic_pred_df['sex'] == 0].shape[0]\n",
    "\n",
    "# false negetive sex == 0\n",
    "fn_1 = logistic_pred_df[logistic_pred_df['salary'] == 1][logistic_pred_df['predict'] == 0][logistic_pred_df['sex'] == 1].shape[0]\n",
    "\n",
    "\n",
    "# true positive sex == 0\n",
    "tp_0 = logistic_pred_df[logistic_pred_df['salary'] == 1][logistic_pred_df['predict'] == 1][logistic_pred_df['sex'] == 0].shape[0]\n",
    "\n",
    "# true positive sex == 1\n",
    "tp_1 = logistic_pred_df[logistic_pred_df['salary'] == 1][logistic_pred_df['predict'] == 1][logistic_pred_df['sex'] == 1].shape[0]\n",
    "\n",
    "n_0 = logistic_pred_df[logistic_pred_df['sex'] == 0].shape[0]\n",
    "n_1 = logistic_pred_df[logistic_pred_df['sex'] == 1].shape[0]\n",
    "\n",
    "tp_1/n_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feaf9de4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression(C=0.5, penalty='l1', solver='liblinear')\n",
    "logistic.fit(x_train, y_train, sample_weight=None)\n",
    "\n",
    "linear = LinearRegression()\n",
    "linear.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84593d4e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, X, y_true):\n",
    "    if isinstance(model, LogisticRegression):\n",
    "        y_pred = model.predict_proba(X)[:, 1]\n",
    "    elif isinstance(model, LinearRegression):\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred >= 0.5)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    return accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daebda9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresion logistica\n",
      "Accuracy: 0.8222449675878539\n",
      "AUC: 0.841712524893063\n",
      "\n",
      "Regresion lineal\n",
      "Accuracy: 0.8106448311156602\n",
      "AUC: 0.8327195990400214\n"
     ]
    }
   ],
   "source": [
    "print('Regresion logistica')\n",
    "accuracy, auc = evaluate(logistic, x_val, y_val)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "print('\\nRegresion lineal')\n",
    "accuracy, auc = evaluate(linear, x_val, y_val)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'AUC: {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97b77666",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logistic_pred_df = train_df.copy()\n",
    "logistic_pred_df['predict'] = logistic.predict(x_train)\n",
    "\n",
    "linear_pred_df = train_df.copy()\n",
    "linear_pred_df['predict'] = linear.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d90d9296",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "text/plain": "        age  education-num  sex  capital-gain  capital-loss  hours-per-week  \\\n12319  29.0           13.0  1.0           0.0           0.0            75.0   \n6964   29.0           16.0  1.0           0.0           0.0            60.0   \n21840  56.0           16.0  1.0           0.0           0.0            50.0   \n19520  63.0           13.0  1.0           0.0           0.0            40.0   \n26360  51.0           13.0  1.0           0.0           0.0            50.0   \n...     ...            ...  ...           ...           ...             ...   \n11321  75.0           10.0  1.0           0.0        1735.0            40.0   \n10328  70.0           14.0  1.0           0.0           0.0             8.0   \n15323  29.0           14.0  1.0           0.0           0.0            60.0   \n32340  75.0           14.0  1.0           0.0           0.0            45.0   \n16868  53.0           12.0  1.0        2407.0           0.0            99.0   \n\n       salary  predict  \n12319     0.0      1.0  \n6964      0.0      1.0  \n21840     0.0      1.0  \n19520     0.0      1.0  \n26360     0.0      1.0  \n...       ...      ...  \n11321     0.0      1.0  \n10328     0.0      1.0  \n15323     0.0      1.0  \n32340     0.0      1.0  \n16868     0.0      1.0  \n\n[897 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>education-num</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>salary</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12319</th>\n      <td>29.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>75.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6964</th>\n      <td>29.0</td>\n      <td>16.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>21840</th>\n      <td>56.0</td>\n      <td>16.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>19520</th>\n      <td>63.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>26360</th>\n      <td>51.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11321</th>\n      <td>75.0</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1735.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10328</th>\n      <td>70.0</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>15323</th>\n      <td>29.0</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>32340</th>\n      <td>75.0</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>45.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16868</th>\n      <td>53.0</td>\n      <td>12.0</td>\n      <td>1.0</td>\n      <td>2407.0</td>\n      <td>0.0</td>\n      <td>99.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>897 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positives\n",
    "logistic_pred_df[logistic_pred_df['salary'] == 0][logistic_pred_df['predict'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9914122",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        age  education-num  sex  capital-gain  capital-loss  hours-per-week  \\\n22278  27.0           10.0  0.0           0.0           0.0            44.0   \n8950   27.0           13.0  0.0           0.0           0.0            40.0   \n7838   25.0           12.0  1.0           0.0           0.0            40.0   \n16505  46.0            3.0  1.0           0.0        1902.0            40.0   \n19140  45.0            7.0  1.0           0.0        2824.0            76.0   \n...     ...            ...  ...           ...           ...             ...   \n19631  34.0           13.0  1.0           0.0           0.0            40.0   \n29694  56.0           13.0  0.0           0.0           0.0            40.0   \n16546  34.0           11.0  1.0           0.0           0.0            40.0   \n17973  25.0            9.0  1.0           0.0           0.0            40.0   \n8057   36.0            9.0  1.0        3464.0           0.0            30.0   \n\n       salary  predict  \n22278     0.0      0.0  \n8950      0.0      0.0  \n7838      0.0      0.0  \n16505     0.0      0.0  \n19140     1.0      1.0  \n...       ...      ...  \n19631     1.0      0.0  \n29694     0.0      0.0  \n16546     0.0      0.0  \n17973     0.0      0.0  \n8057      0.0      0.0  \n\n[22792 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>education-num</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>salary</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22278</th>\n      <td>27.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>44.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8950</th>\n      <td>27.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7838</th>\n      <td>25.0</td>\n      <td>12.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16505</th>\n      <td>46.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1902.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19140</th>\n      <td>45.0</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2824.0</td>\n      <td>76.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19631</th>\n      <td>34.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>29694</th>\n      <td>56.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16546</th>\n      <td>34.0</td>\n      <td>11.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17973</th>\n      <td>25.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8057</th>\n      <td>36.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>3464.0</td>\n      <td>0.0</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>22792 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7373d98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c81d512b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Como el resultado de la diferencia en promedio (mean_difference) es negativo, indica que hay menos resultados favorables para el grupo no privilegiado, por lo que si existe un sesgo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417d4ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.7\n",
    "\n",
    "Pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b2e3dd3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1102230246251565e-16\n",
      "0.9999999999999996\n"
     ]
    },
    {
     "data": {
      "text/plain": "   mean_difference  disparate_impact\n0    -1.110223e-16               1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_difference</th>\n      <th>disparate_impact</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.110223e-16</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "salary_aif_train, salary_aif_test = salary_aif.split([0.7], shuffle=True)\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "\n",
    "pre = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "pre_train = pre.fit_transform(salary_aif_train)\n",
    "pre_train_metric = BinaryLabelDatasetMetric(pre_train,\n",
    "                                        unprivileged_groups=unprivileged_groups,\n",
    "                                        privileged_groups=privileged_groups)\n",
    "\n",
    "# Metricas Pre\n",
    "print(pre_train_metric.mean_difference())\n",
    "print(pre_train_metric.disparate_impact())\n",
    "\n",
    "#df para 1.9\n",
    "df_metricas = pd.DataFrame(data={'mean_difference': [], 'disparate_impact': []})\n",
    "df2 = pd.DataFrame([[pre_train_metric.mean_difference(), pre_train_metric.disparate_impact()]], columns=['mean_difference', 'disparate_impact'])\n",
    "df_metricas = pd.concat([df_metricas, df2])\n",
    "df_metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33451405",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In-Processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4eae073e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\santiago\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "epoch 0; iter: 0; batch classifier loss: 19.136044\n",
      "epoch 1; iter: 0; batch classifier loss: 10.896181\n",
      "epoch 2; iter: 0; batch classifier loss: 13.357958\n",
      "epoch 3; iter: 0; batch classifier loss: 2.912875\n",
      "epoch 4; iter: 0; batch classifier loss: 2.735672\n",
      "epoch 5; iter: 0; batch classifier loss: 2.151693\n",
      "epoch 6; iter: 0; batch classifier loss: 3.599186\n",
      "epoch 7; iter: 0; batch classifier loss: 3.433097\n",
      "epoch 8; iter: 0; batch classifier loss: 1.331930\n",
      "epoch 9; iter: 0; batch classifier loss: 1.083608\n",
      "epoch 10; iter: 0; batch classifier loss: 1.447832\n",
      "epoch 11; iter: 0; batch classifier loss: 1.904807\n",
      "epoch 12; iter: 0; batch classifier loss: 1.467019\n",
      "epoch 13; iter: 0; batch classifier loss: 0.551561\n",
      "epoch 14; iter: 0; batch classifier loss: 0.702436\n",
      "epoch 15; iter: 0; batch classifier loss: 0.459429\n",
      "epoch 16; iter: 0; batch classifier loss: 0.476955\n",
      "epoch 17; iter: 0; batch classifier loss: 0.456829\n",
      "epoch 18; iter: 0; batch classifier loss: 0.383541\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468665\n",
      "epoch 20; iter: 0; batch classifier loss: 0.536764\n",
      "epoch 21; iter: 0; batch classifier loss: 0.455708\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522979\n",
      "epoch 23; iter: 0; batch classifier loss: 0.410881\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457835\n",
      "epoch 25; iter: 0; batch classifier loss: 0.388150\n",
      "epoch 26; iter: 0; batch classifier loss: 0.463302\n",
      "epoch 27; iter: 0; batch classifier loss: 0.488100\n",
      "epoch 28; iter: 0; batch classifier loss: 0.456849\n",
      "epoch 29; iter: 0; batch classifier loss: 0.479487\n",
      "epoch 30; iter: 0; batch classifier loss: 0.342365\n",
      "epoch 31; iter: 0; batch classifier loss: 0.407101\n",
      "epoch 32; iter: 0; batch classifier loss: 0.361023\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421772\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426390\n",
      "epoch 35; iter: 0; batch classifier loss: 0.494204\n",
      "epoch 36; iter: 0; batch classifier loss: 0.390652\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461699\n",
      "epoch 38; iter: 0; batch classifier loss: 0.534203\n",
      "epoch 39; iter: 0; batch classifier loss: 0.305163\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456227\n",
      "epoch 41; iter: 0; batch classifier loss: 0.477138\n",
      "epoch 42; iter: 0; batch classifier loss: 0.400569\n",
      "epoch 43; iter: 0; batch classifier loss: 0.392398\n",
      "epoch 44; iter: 0; batch classifier loss: 0.405926\n",
      "epoch 45; iter: 0; batch classifier loss: 0.360177\n",
      "epoch 46; iter: 0; batch classifier loss: 0.352425\n",
      "epoch 47; iter: 0; batch classifier loss: 0.412478\n",
      "epoch 48; iter: 0; batch classifier loss: 0.385064\n",
      "epoch 49; iter: 0; batch classifier loss: 0.302095\n",
      "-0.2013841129134928\n",
      "0.20773990532455522\n",
      "-0.20582979980109778\n",
      "0.21296144613576745\n"
     ]
    },
    {
     "data": {
      "text/plain": "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x243310a8670>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "salary_aif_train, salary_aif_test = salary_aif.split([0.7], shuffle=True)\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "adversarial= AdversarialDebiasing(privileged_groups=privileged_groups,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    scope_name='plain_classifier',\n",
    "                                    debias=False,\n",
    "                                    sess=sess)\n",
    "adversarial.fit(salary_aif_train)\n",
    "adversarial_train = adversarial.predict(salary_aif_train)\n",
    "adversarial_test = adversarial.predict(salary_aif_test)\n",
    "sess.close()\n",
    "\n",
    "salary_metric_train = BinaryLabelDatasetMetric(adversarial_train,\n",
    "                                               unprivileged_groups=unprivileged_groups,\n",
    "                                               privileged_groups=privileged_groups)\n",
    "salary_metric_test = BinaryLabelDatasetMetric(adversarial_test,\n",
    "                                              unprivileged_groups=unprivileged_groups,\n",
    "                                              privileged_groups=privileged_groups)\n",
    "\n",
    "#In metrics\n",
    "print(salary_metric_train.mean_difference())\n",
    "print(salary_metric_train.disparate_impact())\n",
    "\n",
    "print(salary_metric_test.mean_difference())\n",
    "print(salary_metric_test.disparate_impact())\n",
    "\n",
    "#df para 1.9\n",
    "df3 = pd.DataFrame([[salary_metric_train.mean_difference(), salary_metric_train.disparate_impact()]], columns=['mean_difference', 'disparate_impact'])\n",
    "df4 = pd.DataFrame([[salary_metric_test.mean_difference(), salary_metric_test.disparate_impact()]], columns=['mean_difference', 'disparate_impact'])\n",
    "df_metricas = pd.concat([df_metricas, df3, df4])\n",
    "df_metricas\n",
    "adversarial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a1a3e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e465113",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.198709076817563\n",
      "0.3577001128225591\n"
     ]
    },
    {
     "data": {
      "text/plain": "   mean_difference  disparate_impact\n0    -1.110223e-16          1.000000\n0    -2.013841e-01          0.207740\n0    -2.058298e-01          0.212961\n0    -1.987091e-01          0.357700",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_difference</th>\n      <th>disparate_impact</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.110223e-16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-2.013841e-01</td>\n      <td>0.207740</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-2.058298e-01</td>\n      <td>0.212961</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-1.987091e-01</td>\n      <td>0.357700</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing\n",
    "\n",
    "salary_aif_train, salary_aif_test = salary_aif.split([0.7], shuffle=True)\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "\n",
    "\n",
    "post = CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "post_train = post.fit(salary_aif_train, salary_aif_train)\n",
    "pred_post = post_train.predict(salary_aif_test)\n",
    "post_train_metric = BinaryLabelDatasetMetric(pred_post,\n",
    "                                        unprivileged_groups=unprivileged_groups,\n",
    "                                        privileged_groups=privileged_groups)\n",
    "\n",
    "# Metricas Post\n",
    "print(post_train_metric.mean_difference())\n",
    "print(post_train_metric.disparate_impact())\n",
    "\n",
    "#df para 1.9\n",
    "df5 = pd.DataFrame([[post_train_metric.mean_difference(), post_train_metric.disparate_impact()]], columns=['mean_difference', 'disparate_impact'])\n",
    "df_metricas = pd.concat([df_metricas, df5])\n",
    "df_metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376fd29",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.8\n",
    "Combinacion de los algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ad906e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 14.759559\n",
      "epoch 1; iter: 0; batch classifier loss: 27.664925\n",
      "epoch 2; iter: 0; batch classifier loss: 12.460495\n",
      "epoch 3; iter: 0; batch classifier loss: 3.921125\n",
      "epoch 4; iter: 0; batch classifier loss: 5.631305\n",
      "epoch 5; iter: 0; batch classifier loss: 3.885192\n",
      "epoch 6; iter: 0; batch classifier loss: 5.497898\n",
      "epoch 7; iter: 0; batch classifier loss: 1.268189\n",
      "epoch 8; iter: 0; batch classifier loss: 0.422864\n",
      "epoch 9; iter: 0; batch classifier loss: 1.047125\n",
      "epoch 10; iter: 0; batch classifier loss: 1.014534\n",
      "epoch 11; iter: 0; batch classifier loss: 1.375094\n",
      "epoch 12; iter: 0; batch classifier loss: 0.978358\n",
      "epoch 13; iter: 0; batch classifier loss: 0.441939\n",
      "epoch 14; iter: 0; batch classifier loss: 0.419183\n",
      "epoch 15; iter: 0; batch classifier loss: 0.468893\n",
      "epoch 16; iter: 0; batch classifier loss: 0.463419\n",
      "epoch 17; iter: 0; batch classifier loss: 0.430112\n",
      "epoch 18; iter: 0; batch classifier loss: 0.326501\n",
      "epoch 19; iter: 0; batch classifier loss: 0.408143\n",
      "epoch 20; iter: 0; batch classifier loss: 0.476761\n",
      "epoch 21; iter: 0; batch classifier loss: 0.366151\n",
      "epoch 22; iter: 0; batch classifier loss: 0.318267\n",
      "epoch 23; iter: 0; batch classifier loss: 0.374330\n",
      "epoch 24; iter: 0; batch classifier loss: 0.399214\n",
      "epoch 25; iter: 0; batch classifier loss: 0.426711\n",
      "epoch 26; iter: 0; batch classifier loss: 0.320611\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471442\n",
      "epoch 28; iter: 0; batch classifier loss: 0.393712\n",
      "epoch 29; iter: 0; batch classifier loss: 0.382393\n",
      "epoch 30; iter: 0; batch classifier loss: 0.418613\n",
      "epoch 31; iter: 0; batch classifier loss: 0.372913\n",
      "epoch 32; iter: 0; batch classifier loss: 0.399052\n",
      "epoch 33; iter: 0; batch classifier loss: 0.390881\n",
      "epoch 34; iter: 0; batch classifier loss: 0.396251\n",
      "epoch 35; iter: 0; batch classifier loss: 0.317337\n",
      "epoch 36; iter: 0; batch classifier loss: 0.382782\n",
      "epoch 37; iter: 0; batch classifier loss: 0.414829\n",
      "epoch 38; iter: 0; batch classifier loss: 0.397715\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418201\n",
      "epoch 40; iter: 0; batch classifier loss: 0.372890\n",
      "epoch 41; iter: 0; batch classifier loss: 0.401597\n",
      "epoch 42; iter: 0; batch classifier loss: 0.387702\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398128\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462269\n",
      "epoch 45; iter: 0; batch classifier loss: 0.375210\n",
      "epoch 46; iter: 0; batch classifier loss: 0.387907\n",
      "epoch 47; iter: 0; batch classifier loss: 0.332646\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418077\n",
      "epoch 49; iter: 0; batch classifier loss: 0.380182\n",
      "Algoritmos Juntos: -0.20950500816707776\n",
      "Algoritmos Juntos: 0.22474809655513975\n"
     ]
    },
    {
     "data": {
      "text/plain": "   mean_difference  disparate_impact\n0    -1.110223e-16          1.000000\n0    -2.013841e-01          0.207740\n0    -2.058298e-01          0.212961\n0    -1.987091e-01          0.357700\n0    -2.095050e-01          0.224748",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_difference</th>\n      <th>disparate_impact</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.110223e-16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-2.013841e-01</td>\n      <td>0.207740</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-2.058298e-01</td>\n      <td>0.212961</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-1.987091e-01</td>\n      <td>0.357700</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>-2.095050e-01</td>\n      <td>0.224748</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_aif_train, salary_aif_test = salary_aif.split([0.7], shuffle=True)\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "pre = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "pre_train = pre.fit_transform(salary_aif_train)\n",
    "pre_train_metric = BinaryLabelDatasetMetric(pre_train,\n",
    "                                        unprivileged_groups=unprivileged_groups,\n",
    "                                        privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "adversarial= AdversarialDebiasing(privileged_groups=privileged_groups,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    scope_name='plain_classifier',\n",
    "                                    debias=False,\n",
    "                                    sess=sess)\n",
    "adversarial.fit(pre_train)\n",
    "adversarial_train = adversarial.predict(salary_aif_train)\n",
    "adversarial_test = adversarial.predict(salary_aif_test)\n",
    "sess.close()\n",
    "\n",
    "post = CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "post_train = post.fit(adversarial_train, adversarial_train)\n",
    "pred_post = post_train.predict(adversarial_test)\n",
    "post_train_metric = BinaryLabelDatasetMetric(pred_post,\n",
    "                                        unprivileged_groups=unprivileged_groups,\n",
    "                                        privileged_groups=privileged_groups)\n",
    "\n",
    "print('Algoritmos Juntos:',post_train_metric.mean_difference())\n",
    "print('Algoritmos Juntos:',post_train_metric.disparate_impact())\n",
    "\n",
    "#df para 1.9\n",
    "df6 = pd.DataFrame([[post_train_metric.mean_difference(), post_train_metric.disparate_impact()]], columns=['mean_difference', 'disparate_impact'])\n",
    "df_metricas = pd.concat([df_metricas, df6])\n",
    "df_metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f57e21",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc900b6d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   mean_difference  disparate_impact\nPre_metricas         -1.110223e-16          1.000000\nIn_metricas_train    -2.013841e-01          0.207740\nIn_metricas_test     -2.058298e-01          0.212961\nPost_metricas        -1.987091e-01          0.357700\nMetricas_juntas      -2.095050e-01          0.224748",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_difference</th>\n      <th>disparate_impact</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Pre_metricas</th>\n      <td>-1.110223e-16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>In_metricas_train</th>\n      <td>-2.013841e-01</td>\n      <td>0.207740</td>\n    </tr>\n    <tr>\n      <th>In_metricas_test</th>\n      <td>-2.058298e-01</td>\n      <td>0.212961</td>\n    </tr>\n    <tr>\n      <th>Post_metricas</th>\n      <td>-1.987091e-01</td>\n      <td>0.357700</td>\n    </tr>\n    <tr>\n      <th>Metricas_juntas</th>\n      <td>-2.095050e-01</td>\n      <td>0.224748</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_metricas = df_metricas.rename(index=['Pre_metricas', 'In_metricas_train', 'In_metricas_test' 'Post_metricas', 'Metricas_juntas'])\n",
    "df_metricas.index = ['Pre_metricas', 'In_metricas_train', 'In_metricas_test', 'Post_metricas', 'Metricas_juntas']\n",
    "df_metricas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31bcda0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Parte 2.\n",
    "\n",
    "### 2.1\n",
    "\n",
    "Recordemos que el objetivo de “salary.csv” es predecir quien gana más de 50.000USD. Para poder analizar esto elegimos al grupo privilegiado como los hombres, y el no privilegiado a las mujeres. En general ocupamos dos métricas. (1) mean_difference, en donde restamos los resultados favorables para el grupo privilegiado con el no privilegiado. (2) disparate_imapct, para poder analizar la proporción de resultados favorables para el grupo no privilegiado en comparación con el grupo privilegiado. \n",
    "\n",
    "Aplicando estas métricas al dataset original, considerando los resultados en la parte 1.4. podemos afirmar que hay menos resultados favorables para el grupo no privilegiado (mujeres), y que el grupo privilegiado (hombres) en general gana más que el grupo no privilegiado. Aunque la diferencia es clara, uno podría suponer que la brecha era más grande, y talvez así lo sea, pero el dataset no lo representa. \n",
    "\n",
    "Aplicando el algoritmo de pre-processing “Reweighing”, tenemos que la mean_difference es mayor que en el dataset original, mientras que el disparate_impact está cercano a su valor optimo, el cual es 1, por lo que en proporción gracias a este algoritmo ambos ganan cantidades similares.  \n",
    "\n",
    "En in-processing, utilizamos un algoritmo llamado “AdversarialDebiasing”. Observamos que disparate_impact bajo en comparación con el dataset original, y la mean_difference se acentuó, por lo que por sí solo no es un buen cambio. \n",
    "\n",
    "En post-processing utilizamos “CalibratedEqOddsPostprocessing”. Aquí la mean_difference sigue siendo negativa, y la disparate_impact no está muy cercana a 1, por lo que por sí solo tampoco es un cambio muy útil. \n",
    "\n",
    "Todos los algoritmos juntos tampoco son muy optimistas los cambios, por lo que podemos afirmar con seguridad que ó: (1) No estamos ocupando los algoritmos correctos, ó (2) el dataset ya se encuentra relativamente bien balanceado. En nuestra opinión, esto es mitad verdad, mitad falso. En el dataset original mean_difference era de -0.19, lo cual no es óptimo, pero tampoco terriblemente malo. El disparate_imapct era de 0.36, claramente podría ser mejor y es aquí en donde tal vez mejorar la elección de algoritmos lo haya solucionado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e122b082",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2\n",
    "\n",
    "Podemos sacar 3 conclusiones claras:\n",
    "\n",
    "1.\tDataset original definitivamente tiene sesgo hacia un grupo privilegiado, no es perfecta la distribución, pero claramente podría ser peor. \n",
    "\n",
    "2.\tAlgoritmos que ocupamos no fueron efectivos en balancear el sesgo. \n",
    "\n",
    "3.\tLas dos principales métricas que ocupamos pudieron efectivamente demostrar los sesgos presentes en el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c170b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.3\n",
    "\n",
    "Como solamente pudimos una vez corregir el disparate_impact, el algoritmo de AIF360 llamado “Disparate Impact Remover” podría haber sido útil. Este algoritmo es de tipo pre-processing, se encarga de editar valores de crecimiento para fairness de grupo mientras que preserva el orden dentro de esos mismos grupos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c9440b5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.4\n",
    "\n",
    "1. Statistical Parity Difference: Para la presentación que tenemos en este mismo ramo, discuten un poco de porque es necesario tener un conjunto de imágenes que sea bien representativo, en el caso del paper, paritario en género y tono de color. Este algoritmo consigue la diferencia de los resultados favorables del grupo no privilegiado y el grupo privilegiado, podría ser útil considerando el caso del paper.\n",
    "\n",
    "\n",
    "3. Equal Opportunity Difference: Compañias grandes como amazon ocupan algoritmos para ayudar a contratar nuevos empleados, hay casos detallados en donde sesgos en nuestra cultura se traspasan a estos algoritmos, a veces los acentúan. Para detectar esto Equal Opportunity Difference podría ser útil, ya que devuelve la diferencia de True Positive Rate entre los grupos no privilegiados y los grupos privilegiados.\n",
    "\n",
    "4. Disparate Impact: Si se quiere estudiar y analizar la diferencia de remuneración entre hombres y mujeres, Disparate Impact debería ser útil, ya que devuelve la proporción de resultados favorables entre el grupo no privilegiado y el grupo privilegiado.\n",
    "\n",
    "5. Euclidian Distance: Este está relacionado fuertemente a una presentación de un proyecto que hubo hace poco en la clase de ciencias de datos responsables, en donde con una librería llamada “Word2Vec” detectaban sesgos culturales a lo largo de la historia. En ese paper ocupaban esta métrica para poder analizar mejor esta situación.\n",
    "\n",
    "6. False discovery rate: Porcentaje de falsos positivos dentro de los positivos de un grupo, porcentaje de los clasificados como vegano o vegetariano cuando el individuo es intolerante a la lactoza\n",
    "\n",
    "7. False omission rate: Porcentaje de falsos negativos dentro de los negativos de un grupo, porcentaje de personas blancas que deberían quedar en prison, pero salieron bajo fianza segun compas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f25c330",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3069072",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33d2872c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing\n",
    "\n",
    "\n",
    "class Fairness(StandardDataset):\n",
    "    def __init__(self, df:pd.DataFrame, label_name:str, protected_attribute_names:list, privileged_groups:list, unprivileged_groups:list, *args, **kwargs):\n",
    "\n",
    "        self.__orginal_df = df\n",
    "        self.label_name = label_name\n",
    "        self.protected_attribute_names = protected_attribute_names\n",
    "        self.privileged_groups = privileged_groups\n",
    "        self.unprivileged_groups = unprivileged_groups\n",
    "\n",
    "        # Paso de variable categorica a Numerica\n",
    "\n",
    "        for i in protected_attribute_names:\n",
    "            if df[i].dtype == 'O':\n",
    "                dummie = pd.get_dummies(df[i])\n",
    "                df[i] = dummie[dummie.columns[0]]\n",
    "\n",
    "        if df[label_name].dtype == 'O':\n",
    "            dummie = pd.get_dummies(df[label_name])\n",
    "            df[label_name] = dummie[dummie.columns[0]]\n",
    "\n",
    "        self.df = df\n",
    "\n",
    "        super().__init__(self.df, label_name=self.label_name, protected_attribute_names=self.protected_attribute_names,*args, **kwargs)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def metrics(df):\n",
    "        mean_train = BinaryLabelDatasetMetric(df, unprivileged_groups = df.unprivileged_groups,\n",
    "                                              privileged_groups = df.privileged_groups)\n",
    "\n",
    "        print(\"Diferencia en promedio = %f\" % mean_train.mean_difference())\n",
    "        print(\"Disparidad de impacto = %f\" % mean_train.disparate_impact())\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def pre_processing(df):\n",
    "        pre = Reweighing(unprivileged_groups=df.unprivileged_groups,\n",
    "                         privileged_groups=df.privileged_groups)\n",
    "\n",
    "        return pre.fit_transform(df)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def in_procesing(df):\n",
    "        tf.reset_default_graph()\n",
    "        sess = tf.Session()\n",
    "        adversarial = AdversarialDebiasing(privileged_groups=df.privileged_groups,\n",
    "                                          unprivileged_groups=df.unprivileged_groups,\n",
    "                                          scope_name='plain_classifier',\n",
    "                                          debias=False,\n",
    "                                          sess=sess)\n",
    "        adversarial.fit(df)\n",
    "        adversarial_df = adversarial.predict(df)\n",
    "        sess.close()\n",
    "        return adversarial_df\n",
    "\n",
    "    @staticmethod\n",
    "    def pos_procesing(df):\n",
    "        post = CalibratedEqOddsPostprocessing(unprivileged_groups=df.unprivileged_groups,\n",
    "                                              privileged_groups=df.privileged_groups)\n",
    "        df_post = post.fit(df, df)\n",
    "        return  df_post.predict(df)\n",
    "\n",
    "    @staticmethod\n",
    "    def full_processing(df):\n",
    "        pre = Fairness.pre_processing(df)\n",
    "        in_ = Fairness.in_procesing(pre)\n",
    "        # post = Fairness.pos_procesing(df)\n",
    "        return in_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b97aedd5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 19.760054\n",
      "epoch 0; iter: 200; batch classifier loss: 12.661612\n",
      "epoch 1; iter: 0; batch classifier loss: 5.311508\n",
      "epoch 1; iter: 200; batch classifier loss: 2.393185\n",
      "epoch 2; iter: 0; batch classifier loss: 8.540437\n",
      "epoch 2; iter: 200; batch classifier loss: 2.142355\n",
      "epoch 3; iter: 0; batch classifier loss: 0.853238\n",
      "epoch 3; iter: 200; batch classifier loss: 3.009228\n",
      "epoch 4; iter: 0; batch classifier loss: 1.656756\n",
      "epoch 4; iter: 200; batch classifier loss: 2.848991\n",
      "epoch 5; iter: 0; batch classifier loss: 2.454314\n",
      "epoch 5; iter: 200; batch classifier loss: 2.916402\n",
      "epoch 6; iter: 0; batch classifier loss: 2.130420\n",
      "epoch 6; iter: 200; batch classifier loss: 0.473751\n",
      "epoch 7; iter: 0; batch classifier loss: 0.776780\n",
      "epoch 7; iter: 200; batch classifier loss: 1.613239\n",
      "epoch 8; iter: 0; batch classifier loss: 0.861329\n",
      "epoch 8; iter: 200; batch classifier loss: 0.607151\n",
      "epoch 9; iter: 0; batch classifier loss: 1.006312\n",
      "epoch 9; iter: 200; batch classifier loss: 0.395768\n",
      "epoch 10; iter: 0; batch classifier loss: 0.620954\n",
      "epoch 10; iter: 200; batch classifier loss: 0.509457\n",
      "epoch 11; iter: 0; batch classifier loss: 0.458658\n",
      "epoch 11; iter: 200; batch classifier loss: 0.403802\n",
      "epoch 12; iter: 0; batch classifier loss: 2.140994\n",
      "epoch 12; iter: 200; batch classifier loss: 0.385217\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509090\n",
      "epoch 13; iter: 200; batch classifier loss: 0.606082\n",
      "epoch 14; iter: 0; batch classifier loss: 0.444865\n",
      "epoch 14; iter: 200; batch classifier loss: 0.323889\n",
      "epoch 15; iter: 0; batch classifier loss: 0.427494\n",
      "epoch 15; iter: 200; batch classifier loss: 0.477729\n",
      "epoch 16; iter: 0; batch classifier loss: 0.445113\n",
      "epoch 16; iter: 200; batch classifier loss: 0.399442\n",
      "epoch 17; iter: 0; batch classifier loss: 0.439094\n",
      "epoch 17; iter: 200; batch classifier loss: 0.426272\n",
      "epoch 18; iter: 0; batch classifier loss: 0.433467\n",
      "epoch 18; iter: 200; batch classifier loss: 0.461741\n",
      "epoch 19; iter: 0; batch classifier loss: 0.564443\n",
      "epoch 19; iter: 200; batch classifier loss: 0.368686\n",
      "epoch 20; iter: 0; batch classifier loss: 0.305717\n",
      "epoch 20; iter: 200; batch classifier loss: 0.340834\n",
      "epoch 21; iter: 0; batch classifier loss: 0.369030\n",
      "epoch 21; iter: 200; batch classifier loss: 0.378705\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446289\n",
      "epoch 22; iter: 200; batch classifier loss: 0.433738\n",
      "epoch 23; iter: 0; batch classifier loss: 0.387332\n",
      "epoch 23; iter: 200; batch classifier loss: 0.369007\n",
      "epoch 24; iter: 0; batch classifier loss: 0.402003\n",
      "epoch 24; iter: 200; batch classifier loss: 0.302391\n",
      "epoch 25; iter: 0; batch classifier loss: 0.434388\n",
      "epoch 25; iter: 200; batch classifier loss: 0.390729\n",
      "epoch 26; iter: 0; batch classifier loss: 0.387308\n",
      "epoch 26; iter: 200; batch classifier loss: 0.544306\n",
      "epoch 27; iter: 0; batch classifier loss: 0.346319\n",
      "epoch 27; iter: 200; batch classifier loss: 0.412273\n",
      "epoch 28; iter: 0; batch classifier loss: 0.319371\n",
      "epoch 28; iter: 200; batch classifier loss: 0.443447\n",
      "epoch 29; iter: 0; batch classifier loss: 0.379514\n",
      "epoch 29; iter: 200; batch classifier loss: 0.402747\n",
      "epoch 30; iter: 0; batch classifier loss: 0.429538\n",
      "epoch 30; iter: 200; batch classifier loss: 0.414156\n",
      "epoch 31; iter: 0; batch classifier loss: 0.402104\n",
      "epoch 31; iter: 200; batch classifier loss: 0.417388\n",
      "epoch 32; iter: 0; batch classifier loss: 0.304766\n",
      "epoch 32; iter: 200; batch classifier loss: 0.367981\n",
      "epoch 33; iter: 0; batch classifier loss: 0.388227\n",
      "epoch 33; iter: 200; batch classifier loss: 0.316569\n",
      "epoch 34; iter: 0; batch classifier loss: 0.389315\n",
      "epoch 34; iter: 200; batch classifier loss: 0.404686\n",
      "epoch 35; iter: 0; batch classifier loss: 0.376212\n",
      "epoch 35; iter: 200; batch classifier loss: 0.303384\n",
      "epoch 36; iter: 0; batch classifier loss: 0.290740\n",
      "epoch 36; iter: 200; batch classifier loss: 0.570991\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424833\n",
      "epoch 37; iter: 200; batch classifier loss: 0.336659\n",
      "epoch 38; iter: 0; batch classifier loss: 0.317392\n",
      "epoch 38; iter: 200; batch classifier loss: 0.563943\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479061\n",
      "epoch 39; iter: 200; batch classifier loss: 0.386243\n",
      "epoch 40; iter: 0; batch classifier loss: 0.393960\n",
      "epoch 40; iter: 200; batch classifier loss: 0.405650\n",
      "epoch 41; iter: 0; batch classifier loss: 0.355077\n",
      "epoch 41; iter: 200; batch classifier loss: 0.495441\n",
      "epoch 42; iter: 0; batch classifier loss: 0.396946\n",
      "epoch 42; iter: 200; batch classifier loss: 0.371084\n",
      "epoch 43; iter: 0; batch classifier loss: 0.379503\n",
      "epoch 43; iter: 200; batch classifier loss: 0.324401\n",
      "epoch 44; iter: 0; batch classifier loss: 0.331713\n",
      "epoch 44; iter: 200; batch classifier loss: 0.416439\n",
      "epoch 45; iter: 0; batch classifier loss: 0.383093\n",
      "epoch 45; iter: 200; batch classifier loss: 0.332058\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452895\n",
      "epoch 46; iter: 200; batch classifier loss: 0.444814\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401950\n",
      "epoch 47; iter: 200; batch classifier loss: 0.369749\n",
      "epoch 48; iter: 0; batch classifier loss: 0.347405\n",
      "epoch 48; iter: 200; batch classifier loss: 0.311674\n",
      "epoch 49; iter: 0; batch classifier loss: 0.397015\n",
      "epoch 49; iter: 200; batch classifier loss: 0.350944\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'label_name':'salary', 'protected_attribute_names':['sex'], 'privileged_classes':[[1]], 'favorable_classes':[1],\n",
    "          'features_to_drop':['workclass', 'fnlwgt', 'education', 'marital-status','occupation', 'relationship', 'race', 'native-country'],\n",
    "          'privileged_groups':[{'sex': 1}], 'unprivileged_groups':[{'sex': 0}]\n",
    "          }\n",
    "\n",
    "aa = Fairness(pd.read_csv('salary.csv'), **kwargs)\n",
    "pross = Fairness.full_processing(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296050c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6278adf6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pross_train, pross_test = salary_aif.split([0.7], shuffle=True)\n",
    "pross_test, pross_val = pross_test.split([0.7], shuffle=True)\n",
    "\n",
    "train_df_p, _ = pross_train.convert_to_dataframe()\n",
    "val_df_p, _ = pross_val.convert_to_dataframe()\n",
    "test_df_p, _ = pross_test.convert_to_dataframe()\n",
    "\n",
    "x_train_p = train_df_p.drop('salary', axis=1)\n",
    "y_train_p = train_df_p.salary\n",
    "\n",
    "x_val_p = val_df_p.drop('salary', axis=1)\n",
    "y_val_p = val_df_p.salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7340ee23",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_p = LogisticRegression(C=0.5, penalty='l1', solver='liblinear')\n",
    "logistic_p.fit(x_train, y_train, sample_weight=None)\n",
    "\n",
    "linear_p = LinearRegression()\n",
    "linear_p.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cb19fe9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metricas originales\n",
      "Diferencia en promedio = -0.196276\n",
      "Disparidad de impacto = 0.779599\n",
      "\n",
      "Metricas procesado\n",
      "Diferencia en promedio = -0.124726\n",
      "Disparidad de impacto = 0.864668\n"
     ]
    }
   ],
   "source": [
    "print('Metricas originales')\n",
    "Fairness.metrics(aa)\n",
    "\n",
    "print('\\nMetricas procesado')\n",
    "Fairness.metrics(pross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31175be5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metricas originales\n",
      "\n",
      "Regresion logistica\n",
      "Accuracy: 0.8222449675878539\n",
      "AUC: 0.841712524893063\n",
      "\n",
      "Regresion lineal\n",
      "Accuracy: 0.8106448311156602\n",
      "AUC: 0.8327195990400214\n",
      "\n",
      "\n",
      "Metricas dataset procesado\n",
      "\n",
      "Regresion logistica\n",
      "Accuracy: 0.8263391334015694\n",
      "AUC: 0.8530523621266277\n",
      "\n",
      "Regresion lineal\n",
      "Accuracy: 0.8055271238485159\n",
      "AUC: 0.843753829903635\n"
     ]
    }
   ],
   "source": [
    "print('Metricas originales\\n')\n",
    "\n",
    "print('Regresion logistica')\n",
    "accuracy, auc = evaluate(logistic, x_val, y_val)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "print('\\nRegresion lineal')\n",
    "accuracy, auc = evaluate(linear, x_val, y_val)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "\n",
    "print('\\n\\nMetricas dataset procesado')\n",
    "\n",
    "print('\\nRegresion logistica')\n",
    "accuracy, auc = evaluate(logistic_p, x_val_p, y_val_p)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "print('\\nRegresion lineal')\n",
    "accuracy, auc = evaluate(linear_p, x_val_p, y_val_p)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'AUC: {auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4056a8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Asumo que el item 2.5 va enfocado hacia entender que no es simple procesar estos data sets aun cuando tenemos frameworks o clases especializadas en esto, hay que hacer un trabajo de limpiza y adecuarse a un formato de datos que no es universal, la crase Fairnes creada nos sirve para analizar estos datos pero si modificamos los datos un poco esta dejaria de funcionar.\n",
    "\n",
    "En el campo laboral seria mas adecuado intentar poner un estandar para los dataset para que sea mas facil analizarlos y en empresas mas grandes hay personas especializadas en eso por lo que seria mas simple aplicar los metodos.\n",
    "\n",
    "Con los metodos de fairness pudimos reducir la diferencia de promedio al rededor de un 7% y la disparidad de impacto aumentarla casi 10%, mientras que el acuracy de los modelos no se movio mas de un 1% por lo que creo que el trade off se justifica en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f4248ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}